# M√≥dulo 3 ‚Äî Treinamento de Rede Neural e Sistema de Recomenda√ß√£o

## üìã Vis√£o Geral do Projeto

Este projeto √© um **laborat√≥rio de recomenda√ß√£o de filmes e s√©ries** que utiliza **Redes Neurais** e **TensorFlow.js** para gerar embeddings vetoriais e recomendar conte√∫do com base em **similaridade de cosseno**. O sistema processa a base de dados da Netflix (~8.800 t√≠tulos), vetoriza cada t√≠tulo e permite buscas sem√¢nticas em tempo real.

---

## üß† Classe Principal: Treinamento da Rede Neural

### Arquitetura da Rede Neural

A rede neural √© constru√≠da usando **TensorFlow.js** diretamente no navegador do usu√°rio, sem necessidade de servidor GPU. A arquitetura segue o padr√£o **Encoder/Bottleneck**, semelhante a um Autoencoder:

```
Entrada [256] ‚Üí Dense 512 (ReLU) ‚Üí Dense 256 (ReLU) ‚Üí Dense 128 (Sigmoid) ‚Üí Embedding [128]
```

| Camada | Neur√¥nios | Ativa√ß√£o | Par√¢metros | Fun√ß√£o |
|--------|-----------|----------|------------|--------|
| 1 (Entrada ‚Üí Oculta) | 256 ‚Üí 512 | ReLU | 131.584 | Expande a representa√ß√£o para capturar padr√µes complexos |
| 2 (Oculta ‚Üí Compress√£o) | 512 ‚Üí 256 | ReLU | 131.328 | Comprime, retendo apenas features relevantes |
| 3 (Sa√≠da ‚Äî Embedding) | 256 ‚Üí 128 | Sigmoid | 32.896 | Produz o embedding final normalizado entre 0 e 1 |
| **Total** | | | **295.808** | Par√¢metros trein√°veis |

### Pr√©-processamento: Vetoriza√ß√£o do Texto

Antes de alimentar a rede neural, o texto de cada filme (t√≠tulo + g√™nero + descri√ß√£o + diretor + pa√≠s + rating) √© convertido em um **vetor num√©rico de 256 dimens√µes** usando a t√©cnica **Bag-of-Characters**:

```typescript
const textToInputVector = (text: string): number[] => {
  const vec = new Array(256).fill(0);
  const clean = text.toLowerCase().replace(/[^a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±\s0-9]/g, "");
  for (let i = 0; i < clean.length; i++) {
    vec[clean.charCodeAt(i) % 256] += 1;  // histograma de frequ√™ncia de caracteres
  }
  const max = Math.max(...vec, 1);
  return vec.map(v => v / max);  // normaliza√ß√£o Min-Max entre 0 e 1
};
```

**Como funciona:**
1. O texto √© limpo e convertido para min√∫sculas
2. Cada caractere incrementa a posi√ß√£o correspondente ao seu c√≥digo ASCII no vetor
3. O vetor resultante √© normalizado entre 0 e 1 (Min-Max Scaling)
4. Resultado: vetor de 256 dimens√µes representando a distribui√ß√£o de caracteres do texto

### Constru√ß√£o do Modelo com TensorFlow.js

```typescript
const buildModel = async (tf) => {
  const model = tf.sequential();  // Modelo sequencial: camadas empilhadas

  // Camada 1: 256‚Üí512 neur√¥nios, ativa√ß√£o ReLU
  model.add(tf.layers.dense({ inputShape: [256], units: 512, activation: "relu" }));

  // Camada 2: 512‚Üí256 neur√¥nios, ativa√ß√£o ReLU (gargalo/compress√£o)
  model.add(tf.layers.dense({ units: 256, activation: "relu" }));

  // Camada 3: 256‚Üí128 neur√¥nios, ativa√ß√£o Sigmoid (embedding final)
  model.add(tf.layers.dense({ units: 128, activation: "sigmoid" }));

  model.compile({ optimizer: "adam", loss: "meanSquaredError" });
  return model;
};
```

**M√©todos TensorFlow.js utilizados:**
- `tf.sequential()` ‚Äî Cria modelo sequencial
- `tf.layers.dense()` ‚Äî Camada totalmente conectada
- `model.compile()` ‚Äî Configura otimizador (Adam) e fun√ß√£o de perda (MSE)
- `model.predict()` ‚Äî Forward pass para gerar embedding
- `tf.tensor2d()` ‚Äî Cria tensor 2D a partir de array
- `tensor.data()` ‚Äî Extrai dados do tensor
- `tensor.dispose()` ‚Äî Libera mem√≥ria (previne memory leak)

### Gera√ß√£o do Embedding

```typescript
const generateEmbedding = async (tf, text) => {
  const inputVec = textToInputVector(text);         // Texto ‚Üí vetor 256-dim
  const inputTensor = tf.tensor2d([inputVec], [1, 256]); // Array ‚Üí Tensor
  const outputTensor = model.predict(inputTensor);   // Forward pass: 256‚Üí512‚Üí256‚Üí128
  const embedding = Array.from(await outputTensor.data()); // Tensor ‚Üí Array

  inputTensor.dispose();  // Libera mem√≥ria GPU/CPU
  outputTensor.dispose();

  // Normaliza para vetor unit√°rio (norma L2 = 1)
  const mag = Math.sqrt(embedding.reduce((s, v) => s + v * v, 0));
  return mag > 0 ? embedding.map(v => v / mag) : embedding;
};
```

### Processo de Treinamento (Batch Processing)

O treinamento processa todos os t√≠tulos em lotes de 50 registros:

1. **Inicializa√ß√£o**: Carrega TensorFlow.js e constr√≥i a rede neural
2. **Busca**: Recupera registros da tabela `netflix_titles` do banco externo
3. **Vetoriza√ß√£o**: Para cada t√≠tulo, concatena metadados e gera embedding de 128-dim
4. **Armazenamento**: Salva embeddings na tabela `netflix_embeddings` via Edge Function
5. **Progresso**: Atualiza barra de progresso e logs em tempo real

---

## üîç M√©todo de Recomenda√ß√£o: Similaridade de Cosseno

### Como Funciona a Recomenda√ß√£o

O sistema de recomenda√ß√£o usa **Content-Based Filtering** com **similaridade de cosseno** para encontrar t√≠tulos semelhantes √†s prefer√™ncias do usu√°rio:

```
cos(A, B) = (A ¬∑ B) / (||A|| √ó ||B||)
```

Onde:
- `A ¬∑ B` = produto escalar dos vetores
- `||A||` e `||B||` = normas L2 (magnitudes) dos vetores
- Resultado: valor entre 0 e 1, onde **1 = id√™ntico** e **0 = sem rela√ß√£o**

### Fluxo da Recomenda√ß√£o

```
Usu√°rio seleciona filtros (tipo, g√™nero, tom, dura√ß√£o, pa√≠s)
        ‚Üì
Filtros s√£o concatenados em texto de consulta
        ‚Üì
TensorFlow.js gera embedding de 128-dim da consulta (mesma rede neural do treinamento)
        ‚Üì
Embedding √© enviado ao banco PostgreSQL externo via Edge Function
        ‚Üì
SQL calcula similaridade de cosseno contra todos os vetores armazenados
        ‚Üì
Resultados ordenados por maior similaridade s√£o retornados
        ‚Üì
Interface exibe t√≠tulos com porcentagem de acur√°cia (similaridade)
```

### C√°lculo SQL da Similaridade

A similaridade de cosseno √© calculada diretamente no PostgreSQL para m√°xima efici√™ncia:

```sql
SELECT
  title, type, listed_in, description,
  (SUM(a * b)) / (SQRT(SUM(a*a)) * SQRT(SUM(b*b))) AS similarity
FROM netflix_embeddings,
  UNNEST(embedding, query_embedding) AS t(a, b)
GROUP BY show_id
ORDER BY similarity DESC
LIMIT 12;
```

### Interpreta√ß√£o dos Resultados

| Similaridade | Significado |
|--------------|-------------|
| 90-100% | Conte√∫do muito similar ao crit√©rio buscado |
| 70-89% | Boa correspond√™ncia, conte√∫do relacionado |
| 50-69% | Correspond√™ncia moderada |
| < 50% | Pouca rela√ß√£o com os crit√©rios |

---

## üèóÔ∏è Estrutura do Projeto

```
src/
‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx          # Vis√£o geral com dados reais do banco externo
‚îÇ   ‚îú‚îÄ‚îÄ ImportCSV.tsx          # Importa√ß√£o de dados CSV para o banco
‚îÇ   ‚îú‚îÄ‚îÄ TrainModel.tsx         # Treinamento da rede neural (classe principal)
‚îÇ   ‚îú‚îÄ‚îÄ TestRecommendation.tsx # Teste de recomenda√ß√µes com logs detalhados
‚îÇ   ‚îî‚îÄ‚îÄ TechnicalExplanation.tsx # Explica√ß√£o t√©cnica do sistema
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ Sidebar.tsx            # Navega√ß√£o lateral
‚îÇ   ‚îú‚îÄ‚îÄ Header.tsx             # Cabe√ßalho das p√°ginas
‚îÇ   ‚îú‚îÄ‚îÄ MovieCard.tsx          # Card de exibi√ß√£o de filme/s√©rie
‚îÇ   ‚îú‚îÄ‚îÄ StatCard.tsx           # Card de estat√≠stica
‚îÇ   ‚îî‚îÄ‚îÄ ProgressBar.tsx        # Barra de progresso
‚îî‚îÄ‚îÄ mock/
    ‚îú‚îÄ‚îÄ movies.ts              # Tipos e op√ß√µes de filtro
    ‚îî‚îÄ‚îÄ stats.ts               # Dados est√°ticos (fallback)

supabase/functions/
‚îú‚îÄ‚îÄ external-db/index.ts       # Edge Function: ponte com banco PostgreSQL externo
‚îî‚îÄ‚îÄ train-model/index.ts       # Edge Function: treinamento (backup)
```

## üóÑÔ∏è Banco de Dados Externo (PostgreSQL)

### Tabela `netflix_titles`
Armazena os dados brutos importados do CSV (~8.809 registros):

| Coluna | Tipo | Descri√ß√£o |
|--------|------|-----------|
| show_id | TEXT (PK) | Identificador √∫nico |
| type | TEXT | "Movie" ou "TV Show" |
| title | TEXT | Nome do t√≠tulo |
| director | TEXT | Diretor(es) |
| cast | TEXT | Elenco |
| country | TEXT | Pa√≠s de origem |
| release_year | INTEGER | Ano de lan√ßamento |
| rating | TEXT | Classifica√ß√£o et√°ria |
| duration | TEXT | Dura√ß√£o (minutos ou temporadas) |
| listed_in | TEXT | G√™neros/categorias |
| description | TEXT | Sinopse |

### Tabela `netflix_embeddings`
Armazena os vetores gerados pela rede neural:

| Coluna | Tipo | Descri√ß√£o |
|--------|------|-----------|
| id | SERIAL (PK) | ID auto-incremento |
| show_id | TEXT (UNIQUE) | Refer√™ncia ao t√≠tulo |
| title | TEXT | Nome do t√≠tulo |
| type | TEXT | Tipo do conte√∫do |
| listed_in | TEXT | G√™neros |
| description | TEXT | Sinopse |
| embedding | DOUBLE PRECISION[] | Vetor de 128 dimens√µes |
| created_at | TIMESTAMP | Data de cria√ß√£o |

## ‚öôÔ∏è Tecnologias Utilizadas

| Tecnologia | Uso |
|-----------|-----|
| **React 18** | Interface do usu√°rio (SPA) |
| **TypeScript** | Tipagem est√°tica |
| **TensorFlow.js** | Rede neural no navegador |
| **Tailwind CSS** | Estiliza√ß√£o |
| **Framer Motion** | Anima√ß√µes |
| **Recharts** | Gr√°ficos (dashboard) |
| **PostgreSQL** | Banco de dados externo |
| **Supabase Edge Functions** | Backend serverless (ponte com banco externo) |
| **Vite** | Bundler e dev server |

## üöÄ Como Executar

1. Clone o reposit√≥rio
2. Instale as depend√™ncias: `npm install`
3. Configure as vari√°veis de ambiente (`.env`)
4. Inicie o servidor de desenvolvimento: `npm run dev`

### Fluxo de Uso

1. **Importar CSV** ‚Äî Carregue o arquivo `netflix_titles.csv` na p√°gina de importa√ß√£o
2. **Treinar Modelo** ‚Äî Gere os embeddings vetoriais clicando em "Gerar Embeddings"
3. **Testar Recomenda√ß√£o** ‚Äî Selecione crit√©rios e gere recomenda√ß√µes com similaridade de cosseno
4. **Dashboard** ‚Äî Visualize estat√≠sticas em tempo real do banco de dados
5. **Explica√ß√£o T√©cnica** ‚Äî Consulte a documenta√ß√£o detalhada do sistema

---

## üìö Conceitos-Chave

- **Embedding**: Representa√ß√£o num√©rica densa de dados em espa√ßo vetorial de alta dimens√£o
- **Bag-of-Characters**: T√©cnica de vetoriza√ß√£o baseada na frequ√™ncia de caracteres
- **Similaridade de Cosseno**: Medida do √¢ngulo entre dois vetores (0 a 1)
- **Content-Based Filtering**: Recomenda√ß√£o baseada nas caracter√≠sticas do pr√≥prio conte√∫do
- **Forward Pass**: Propaga√ß√£o dos dados atrav√©s das camadas da rede neural
- **ReLU (Rectified Linear Unit)**: Fun√ß√£o de ativa√ß√£o f(x) = max(0, x)
- **Sigmoid**: Fun√ß√£o de ativa√ß√£o que mapeia valores entre 0 e 1
- **Adam Optimizer**: Algoritmo de otimiza√ß√£o com taxa de aprendizado adaptativa
